{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet_1025_same_pic_train_1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# number 1 to 10 data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# 每個 MNIST 中的圖片都有一個對應的 label 也就是從 0 到 9 的數值．\n",
    "# 在這裡每個 label 都是一個 one-hot vectors\n",
    "# one-hot vector 是指法就是 [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 觀察資料型態\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"讓我們看一下 MNIST 訓練還有測試的資料集長得如何\")\n",
    "#print (\"mnist資料型態 : %s \" %(type(mnist)))\n",
    "print (\"mnist資料型態 : \" + str(type(mnist)))\n",
    "print (\"training sample 共有 %s 個\"%(mnist.train.num_examples))\n",
    "print (\"validation sample 共有 %s 個\" %(mnist.validation.num_examples))\n",
    "print (\"testing sample 共有 %s 個\"  %(mnist.test.num_examples))\n",
    "train_img = mnist.train.images\n",
    "train_label = mnist.train.labels\n",
    "test_img = mnist.test.images\n",
    "test_label = mnist.test.labels\n",
    "print(\"train_img 的 type : %s\" % (type(train_img)))\n",
    "print(\"train_img 的 dimension : %s\" % (train_img.shape,))\n",
    "print(\"train_label 的 type : %s\" % (type(train_label)))\n",
    "print(\"train_label 的 dimension : %s\" % (train_label.shape,))\n",
    "print(\"test_img 的 type : %s\" % (type(test_img)))\n",
    "print(\"test_img 的 dimension : %s\" % (test_img.shape,))\n",
    "print(\"test_label 的 type : %s\" % (type(test_label)))\n",
    "print(\"test_label 的 dimension : %s\" % (test_label.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定義函數(印出用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_pic(origin, size, channel, xsnum):\n",
    "    pic = origin[xsnum] #第num張照片 \n",
    "    ch = pic.transpose(2,0,1).reshape([channel,-1]) #將照片拉成數個channel\n",
    "    out = ch.reshape([size*channel,size]) #將第cnum的channel照片拉成28x28\n",
    "#     print(\"\\n*********************************************************************************\\n\")    \n",
    "#     print (\"pic shape:\" + str(pic.shape))\n",
    "#     print (\"ch shape:\" + str(ch.shape))\n",
    "    print (\"output shape:\" + str(out.shape))\n",
    "#     print(\"\\n*********************************************************************************\\n\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def print_pic_int(x):\n",
    "    print(\"\\n*********************************************************************************\\n\")\n",
    "\n",
    "    j = 0\n",
    "    while j < (x.shape[0]) :\n",
    "        print (str(int(round(x[j,0])))+ \" \"+ str(int(round(x[j,1])))\n",
    "            + \" \"+ str(int(round(x[j,2])))+ \" \"+ str(int(round(x[j,3])))\n",
    "            + \" \"+ str(int(round(x[j,4])))+ \" \"+ str(int(round(x[j,5])))\n",
    "            + \" \"+ str(int(round(x[j,6])))+ \" \"+ str(int(round(x[j,7])))\n",
    "            + \" \"+ str(int(round(x[j,8])))+ \" \"+ str(int(round(x[j,9])))\n",
    "            + \" \"+ str(int(round(x[j,10])))+ \" \"+ str(int(round(x[j,11])))\n",
    "            + \" \"+ str(int(round(x[j,12])))+ \" \"+ str(int(round(x[j,13])))\n",
    "            + \" \"+ str(int(round(x[j,14])))+ \" \"+ str(int(round(x[j,15])))\n",
    "            + \" \"+ str(int(round(x[j,16])))+ \" \"+ str(int(round(x[j,17])))\n",
    "            + \" \"+ str(int(round(x[j,18])))+ \" \"+ str(int(round(x[j,19])))\n",
    "            + \" \"+ str(int(round(x[j,20])))+ \" \"+ str(int(round(x[j,21])))\n",
    "            + \" \"+ str(int(round(x[j,22])))+ \" \"+ str(int(round(x[j,23])))\n",
    "            + \" \"+ str(int(round(x[j,24])))+ \" \"+ str(int(round(x[j,25])))\n",
    "            + \" \"+ str(int(round(x[j,26])))+ \" \"+ str(int(round(x[j,27]))))\n",
    "        j += 1    \n",
    "        if(j% (x.shape[1]) == 0):\n",
    "            print(\"\\n*********************************************************************************\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_pic_prec(x , prec):\n",
    "    print (\"test printing by num:\")\n",
    "    i = 0\n",
    "    print(\"\\n*********************************************************************************\\n\")\n",
    "    \n",
    "    while i < (x.shape[0]) :\n",
    "        print  (str(round(x[i,0], prec))+ \"\\t\"+ str(round(x[i,1], prec))\n",
    "            + \"\\t\"+ str(round(x[i,2], prec))+ \"\\t\"+ str(round(x[i,3], prec))\n",
    "            + \"\\t\"+ str(round(x[i,4], prec))+ \"\\t\"+ str(round(x[i,5], prec))\n",
    "            + \"\\t\"+ str(round(x[i,6], prec))+ \"\\t\"+ str(round(x[i,7], prec))\n",
    "            + \"\\t\"+ str(round(x[i,8], prec))+ \"\\t\"+ str(round(x[i,9], prec))\n",
    "            + \"\\t\"+ str(round(x[i,10], prec))+ \"\\t\"+ str(round(x[i,11], prec))\n",
    "            + \"\\t\"+ str(round(x[i,12], prec))+ \"\\t\"+ str(round(x[i,13], prec))\n",
    "            + \"\\t\"+ str(round(x[i,14], prec))+ \"\\t\"+ str(round(x[i,15], prec))\n",
    "            + \"\\t\"+ str(round(x[i,16], prec))+ \"\\t\"+ str(round(x[i,17], prec))\n",
    "            + \"\\t\"+ str(round(x[i,18], prec))+ \"\\t\"+ str(round(x[i,19], prec))\n",
    "            + \"\\t\"+ str(round(x[i,20], prec))+ \"\\t\"+ str(round(x[i,21], prec))\n",
    "            + \"\\t\"+ str(round(x[i,22], prec))+ \"\\t\"+ str(round(x[i,23], prec))\n",
    "            + \"\\t\"+ str(round(x[i,24], prec))+ \"\\t\"+ str(round(x[i,25], prec))\n",
    "            + \"\\t\"+ str(round(x[i,26], prec))+ \"\\t\"+ str(round(x[i,27], prec)))\n",
    "        i += 1\n",
    "        if(i% (x.shape[1]) == 0):\n",
    "             print(\"\\n*********************************************************************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印出 filter 函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print_pic_prec(reshape_pic(W_conv1,5,6,0),2)\n",
    "def print_filter():\n",
    "#     print (sess.run(W_conv1[0]).shape)\n",
    "#     print (sess.run(W_conv1).shape)\n",
    "    i = 0\n",
    "    filter_no = 0\n",
    "    #while filter_no < 5:\n",
    "    while i < 5:\n",
    "        print (str(sess.run(W_conv1[0,i,0,filter_no]))+\"\\t\"\n",
    "        +str(sess.run(W_conv1[1,i,0,filter_no]))+\"\\t\"\n",
    "        +str(sess.run(W_conv1[2,i,0,filter_no]))+\"\\t\"\n",
    "        +str(sess.run(W_conv1[3,i,0,filter_no]))+\"\\t\"\n",
    "        +str(sess.run(W_conv1[4,i,0,filter_no]))+\"\\t\")\n",
    "        i+=1\n",
    "   #     filter_no+=1\n",
    "   #     i=0\n",
    "\n",
    "# print (sess.run(W_conv1[0], feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印出結果 函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_result():\n",
    "#     print (\"prediction shape : \" + str(prediction[0].shape))\n",
    "#     print(\"\\n*********************************************************************************\\n\")\n",
    "    print (sess.run(prediction[0], feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 函數定義區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1}) #feee_dict 餵字串\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1)) #使用argmax函數\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,mean=0, stddev=0.1)  #設定weight mean dev\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape) #設定bias\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 訓練過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# define placeholder for inputs to network\n",
    "# xs = tf.placeholder(tf.float32, [None, 784]) \n",
    "# print (xs)\n",
    "# print (sess.run(xs))\n",
    "# xs = tf.placeholder(tf.float32, [None, 784])/255  \n",
    "# print (xs)\n",
    "# print (sess.run(xs))\n",
    "xs = tf.placeholder(tf.float32, [None, 784])/255.  \n",
    "# print (xs)\n",
    "# print (sess.run(xs))\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)  # The keep_prob value is used to control the dropout rate used when training the neural network. \n",
    "x_image = tf.reshape(xs, [-1, 28, 28, 1]) # 784 -> 28x28\n",
    "# print(x_image.shape)  # [n_samples, 28,28,1]\n",
    "\n",
    "## conv1 layer ##\n",
    "W_conv1 = weight_variable([5,5,1,6]) # patch 5x5, in size 1, out size 6\n",
    "b_conv1 = bias_variable([6])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 28x28x6\n",
    "h_pool1 = max_pool_2x2(h_conv1)                                         # output size 14x14x32\n",
    "\n",
    "## conv2 layer ##\n",
    "W_conv2 = weight_variable([5,5, 6, 16]) # patch 5x5, in size 32, out size 64\n",
    "b_conv2 = bias_variable([16])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 14x14x64\n",
    "h_pool2 = max_pool_2x2(h_conv2)                                         # output size 7x7x64\n",
    "\n",
    "## fc1 layer ##\n",
    "W_fc1 = weight_variable([7*7*16, 120])\n",
    "b_fc1 = bias_variable([120])\n",
    "# [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*16])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "## fc2 layer ##\n",
    "W_fc2 = weight_variable([120, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))       # loss 接着呢我们利用交叉熵损失函数来定义我们的cost function\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)  # 我们用tf.train.AdamOptimizer()作为我们的优化器进行优化，使我们的cross_entropy最小\n",
    "\n",
    "sess = tf.Session() #定义Session\n",
    "# important step\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1: # # tf.initialize_all_variables() 这种写法马上就要被废弃\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 決定訓練次數與計算訓練精準度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_xs, batch_ys = mnist.train.next_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "#     print (\"第1張圖的 shape : \" + str(x_image.shape))\n",
    "#     px1 = sess.run(x_image, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "#     plt.imshow(reshape_pic(px1,28,1,0), cmap='Greys')  \n",
    "#     plt.show()\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})    \n",
    "#     if(i % 10 == 0):\n",
    "#         print (\"已經訓練完\"+str(int(i)+1)+\"次\")\n",
    "    if(i == 0):\n",
    "        print (\"訓練用圖長相：\")\n",
    "        px1 = sess.run(x_image, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "        plt.imshow(reshape_pic(px1,28,1,0), cmap='Greys')  \n",
    "        plt.show()\n",
    "        print (\"第\"+str(int(i)+1)+\"次的精確度： \"+str(compute_accuracy(mnist.test.images[:1000], mnist.test.labels[:1000])))\n",
    "        print (\"filter 長相：\")\n",
    "        print_filter()    \n",
    "        print (\"預測結果：\")\n",
    "        print_result()\n",
    "        print(\"\\n*********************************************************************************\\n\")\n",
    "        train1=sess.run(W_conv1)\n",
    "    if(i == 99):\n",
    "        print (\"第\"+str(int(i)+1)+\"次的精確度： \"+str(compute_accuracy(mnist.test.images[:1000], mnist.test.labels[:1000])))\n",
    "        print (\"filter 長相：\")\n",
    "        print_filter()\n",
    "        print (\"預測結果：\")\n",
    "        print_result()\n",
    "        print(\"\\n*********************************************************************************\\n\")\n",
    "        train100=sess.run(W_conv1)\n",
    "    if(i == 999):\n",
    "        print (\"第\"+str(int(i)+1)+\"次的精確度： \"+str(compute_accuracy(mnist.test.images[:1000], mnist.test.labels[:1000])))\n",
    "        print (\"filter 長相：\")\n",
    "        print_filter()\n",
    "        print (\"預測結果：\")\n",
    "        print_result()\n",
    "        print(\"\\n*********************************************************************************\\n\")\n",
    "        train1000=sess.run(W_conv1)\n",
    "        \n",
    "\n",
    "# 训练数据，我们假定训练1000步，每50步输出一下准确率， 注意sess.run()时记得要用feed_dict给我们的众多 placeholder 喂数据哦.\n",
    "# 以上呢就是一个简单的卷积神经网络的例子代码            \n",
    "# for i in range(1000):\n",
    "#     batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "#     sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "#     if i % 50 == 0:\n",
    "#         print (\"第\"+str(int(i/50)+1)+\"次的精確度： \"+str(compute_accuracy(\n",
    "#             mnist.test.images[:1000], mnist.test.labels[:1000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter 相減\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_result = np.subtract(train100,train1)\n",
    "i = 0\n",
    "filter_no = 0\n",
    "print(\"\\n train100 - train1 : \\n\")\n",
    "while i < 5:\n",
    "    print (str(train_result[0,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[1,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[2,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[3,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[4,i,0,filter_no])+\"\\t\")\n",
    "    i+=1\n",
    "print(\"\\n*********************************************************************************\\n\")\n",
    "    \n",
    "train_result = np.subtract(train1000,train1)\n",
    "i = 0\n",
    "filter_no = 0\n",
    "print(\"\\n train1000 - train1 : \\n\")\n",
    "while i < 5:\n",
    "    print (str(train_result[0,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[1,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[2,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[3,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[4,i,0,filter_no])+\"\\t\")\n",
    "    i+=1\n",
    "print(\"\\n*********************************************************************************\\n\")    \n",
    "\n",
    "train_result = np.subtract(train1000,train100)\n",
    "i = 0\n",
    "filter_no = 0\n",
    "print(\"\\n train1000 - train100 : \\n\")\n",
    "while i < 5:\n",
    "    print (str(train_result[0,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[1,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[2,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[3,i,0,filter_no])+\"\\t\"\n",
    "        +str(train_result[4,i,0,filter_no])+\"\\t\")\n",
    "    i+=1    \n",
    "print(\"\\n*********************************************************************************\\n\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印出結果---input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"第1張圖的 shape : \" + str(x_image.shape))\n",
    "px1 = sess.run(x_image, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "plt.imshow(reshape_pic(px1,28,1,0), cmap='Greys')  \n",
    "\n",
    "# print_pic_prec(reshape_pic(px1,28,1,0),5)\n",
    "# print_pic_int(reshape_pic(px1,28,1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印出結果---conv 1層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    print (\"conv1 shape : \" + str(h_conv1.shape))\n",
    "    pC1 = sess.run(h_conv1, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "    plt.imshow(reshape_pic(pC1,28,6,0), cmap='Greys')\n",
    "\n",
    "#     print_pic_prec(reshape_pic(pC1,28,6,0),3)\n",
    "#     print_pic_int(reshape_pic(pC1,28,6,0))\n",
    "    \n",
    "    # print(\"\\n*********************************************************************************\\n\")\n",
    "    # print (\"reshape pic shape:\" + str((reshape_pic(pC1,28,6,0)).shape))\n",
    "    # print (\"content:\\n\" + str(reshape_pic(pC1,28,6,0)))\n",
    "    # print(\"\\n*********************************************************************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印出結果---pool 1層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print (\"pool1 shape : \" + str(h_pool1.shape))\n",
    "    pH1 = sess.run(h_pool1, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "    plt.imshow(reshape_pic(pH1,14,6,0), cmap='Greys')\n",
    "    \n",
    "    #print_pic_prec(reshape_pic(pH1,14,6,0),3)\n",
    "    #print_pic_int(reshape_pic(pH1,14,6,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印出結果---conv 2層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print (\"conv2 shape : \" + str(h_conv2.shape))\n",
    "    pC2 = sess.run(h_conv2, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "    plt.imshow(reshape_pic(pC2,14,16,0), cmap='Greys')\n",
    "    \n",
    "    #print_pic_prec(reshape_pic(pC2,14,16,0),3)\n",
    "    #print_pic_int(reshape_pic(pC2,14,16,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印出結果---pool 2層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print (\"pool2 shape : \" + str(h_pool2.shape))\n",
    "    pH2 = sess.run(h_pool2, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "    plt.imshow(reshape_pic(pH2,7,16,0), cmap='Greys')\n",
    "    \n",
    "    #print_pic_prec(reshape_pic(pH2,7,16,0),3)\n",
    "    #print_pic_int(reshape_pic(pH2,7,16,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印出結果---fc 1層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print (\"fc1 shape : \" + str(h_fc1[0].shape))\n",
    "    print(\"\\n*********************************************************************************\\n\")\n",
    "    print (sess.run(h_fc1[0], feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 印出結果---fc 2層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print (\"prediction shape : \" + str(prediction[0].shape))\n",
    "    print(\"\\n*********************************************************************************\\n\")\n",
    "    print (sess.run(prediction[0], feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5}))\n",
    "#     pH2 = sess.run(h_pool2, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "#     plt.imshow(reshape_pic(pH2,7,16,0), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 參考資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CNN code 詳細說明 CNN 卷积神经网络 3](https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-05-CNN3/)\n",
    "\n",
    "[TensorFlow入门 数据与参数的输入](https://zhuanlan.zhihu.com/p/25307881)\n",
    "\n",
    "[Tensorflow Day3 : 熟悉 MNIST 手寫數字辨識資料集 ](https://ithelp.ithome.com.tw/articles/10186473)\n",
    "\n",
    "[tensorflow教學(4) -- 建置一個CNN網路分辨手寫辨識字](http://darren1231.pixnet.net/blog/post/332753859-tensorflow%E6%95%99%E5%AD%B8----%E5%BB%BA%E7%BD%AE%E4%B8%80%E5%80%8Bcnn%E7%B6%B2%E8%B7%AF%E5%88%86%E8%BE%A8%E6%89%8B%E5%AF%AB%E8%BE%A8%E8%AD%98)\n",
    "\n",
    "[原创#Deep Learning回顾#之LeNet、AlexNet、GoogLeNet、VGG、ResNet](https://zhuanlan.zhihu.com/p/22094600)\n",
    "\n",
    "[干货|详解CNN五大经典模型:Lenet，Alexnet，Googlenet，VGG，DRL](http://www.sohu.com/a/134347664_642762)\n",
    "\n",
    "[Tensorflow Day3 : 熟悉 MNIST 手寫數字辨識資料集 ](https://ithelp.ithome.com.tw/articles/10186473)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
